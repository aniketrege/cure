<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="CuRe introduces a scalable dataset and scoring suite to expose cultural gaps in popular text‑to‑image models and quantify long‑tail bias.">
  <meta name="keywords" content="CuRe, Cultural Representativeness, Text‑to‑Image, Long‑Tail Bias, Benchmark, T2I">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CuRe: Cultural Gaps in the Long‑Tail of Text‑to‑Image Models</title>

  <!-- Optional analytics removed. If you need analytics, insert your own tag. -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://aniketrege.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

<!--       <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">HyperNeRF</a>
          <a class="navbar-item" href="https://nerfies.github.io">Nerfies</a>
          <a class="navbar-item" href="https://latentfusion.github.io">LatentFusion</a>
          <a class="navbar-item" href="https://photoshape.github.io">PhotoShape</a>
        </div>
      </div> -->
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CuRe: Cultural Gaps in the Long‑Tail of Text‑to‑Image Systems</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://aniketrege.github.io">Aniket Rege</a><sup>*1</sup>,</span>
            <span class="author-block"><a href="https://www.linkedin.com/in/zinnia-nie-468850224/">Zinnia Nie</a><sup>1</sup>,</span> 
            <span class="author-block"><a href="https://www.linkedin.com/in/mahesh-r-21a4981a4">Mahesh Ramesh</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://www.linkedin.com/in/unmesh-raskar/">Unmesh Raskar</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://www.zhuoranyu.com/">Zhuoran Yu</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://adityakusupati.github.io/">Aditya Kusupati</a><sup>2†</sup>,</span>
            <span class="author-block"><a href="https://pages.cs.wisc.edu/~yongjaelee/">Yong Jae Lee</a><sup>1†</sup>,</span>
            <span class="author-block"><a href="https://ramyakv.github.io/">Ramya Korlakai Vinayak</a><sup>1†</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Wisconsin‑Madison&nbsp;&nbsp;</span>
            <span class="author-block"><sup>2</sup>University of Washington</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./static/paper/CuRe_paper.pdf" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2404.xxxxx" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/aniketrege/cure" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span><span>Code & Dataset</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Hero teaser image (replace src with Figure 1 composite) -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure>
        <img src="./static/images/image.png" width="1000" height="800" alt="CuRe pottery teaser showing cultural gaps in T2I models">
      </figure>
      <h2 class="subtitle has-text-centered">
        CuRe reveals how state‑of‑the‑art text‑to‑image systems under‑represent the cultural <b>long tail</b>.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>Popular text‑to‑image (T2I) systems are trained on web‑scale data that is heavily Amero and Euro‑centric, leading to hallucinations and misrepresentation for cultures in the Global South. We introduce <b>CuRe</b>, a benchmarking suite that diagnoses these cultural gaps.</p>
          <p>CuRe couples a <b>hierarchical dataset</b> of <b>300</b> cultural artifacts across <b>64</b> global regions with <b>marginal‑information attribution scorers</b> that better match human judgments of cultural representativeness, image‑text alignment and diversity. Our analysis shows that mainstream T2I systems perform well on concepts widely seen during pretraining (the "head" of the distribution) like (a) <i>ceramic diyas</i> from India but fail on long‑tail artifacts such as (b) <i>jebena</i> from Ethiopia or (c) <i>amphora of Hermonax</i> from Greece, even when additional attributes are provided in the text prompt.</p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<!-- ───────────────── Motivation / Problem ───────────────── -->
<section id="motivation" class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Why CuRe?</h2>
    <div class="content">
      <ul>
        <li>Current text-to-image (T2I) systems <strong>do not represent global cultures equitably</strong>.</li>
        <li>America + Europe dominate pre-training data (<em>“head”</em>), while the Global South lives in the <em>long tail</em>.</li>
        <li>CuRe asks: <em>How faithfully can T2I models generate images for those under-represented cultures?</em></li>
      </ul>
    </div>
  </div>
</section>

<!-- ──────────────── Dataset & Benchmark ──────────────── -->
<section id="dataset" class="section is-light">
  <div class="container is-max-desktop">

    <h2 class="title is-3">A New Benchmark & Dataset</h2>

    <!-- FULL-WIDTH FIGURE ABOVE -->
    <figure class="image mb-5">
      <img src="./static/images/cure_system_diagram.jpg"
           alt="Hierarchical view of CuRe artifacts" />
    </figure>

    <!-- TEXT CONTENT BELOW -->
    <div class="content">
      <p>
        The <strong>CuRe Dataset</strong> couples <b>300</b> cultural artifacts from
        <b>64 regions</b> inside a three-level hierarchy:
      </p>
      <ul>
        <li><code>s</code> - <b>super-category</b> (e.g.&nbsp;Art, Fashion, Food)</li>
        <li><code>c</code> - <b>category</b> (e.g.&nbsp;Dumpling)</li>
        <li><code>n</code> - <b>artifact name</b> (e.g.&nbsp;Banku)</li>
        <li><code>r</code> - <b>region</b> (e.g.&nbsp;Ghana)</li>
      </ul>
      <p>
        This structure lets us ask: “How far down the long tail can a T2I model go
        <em>and still be faithful</em>?”
      </p>
    </div>

  </div>
</section>

<!-- ─────────────────── CuRe Scorers ──────────────────── -->
<section id="scorers" class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">CuRe Scorers: Measuring Cultural Representativeness</h2>

    <!-- PIPELINE DIAGRAM -->
    <div class="columns is-vcentered mb-6">
      <div class="column is-one-half">
        <figure class="image">
          <img src="./static/images/cure_dataset.jpg"
               alt="CuRe scorer pipeline and user-study overview" />
        </figure>
      </div>

      <div class="column">
        <p class="content">
          We inject <em>marginal information</em> gradually adding name (<code>n</code>),
          region (<code>r</code>), category (<code>c</code>),into the prompt and feed
          it through a T2I model <code>f<sub>θ</sub></code>.  
          A quantitative scorer <code>φ</code> produces a “rep’ness” report card.
        </p>
        <p class="content">
          Human raters who self-identify with the culture supply the gold judgment
          <code>φ<sup>*</sup></code>, letting us see which automatic metrics
          actually track human perception.
        </p>
      </div>
    </div>

    <!-- METRICS PANEL -->
    <figure class="image">
      <img src="./static/images/cure-image3.jpg"
           alt="Examples of φPS, φITA, φDIV metrics and why baselines fail" />
    </figure>

    <div class="content mt-4">
      <ul>
        <li><b>φ<sub>PS</sub></b> – Perceptual Similarity: visual closeness to its category.</li>
        <li><b>φ<sub>ITA</sub></b> – Image/Text Alignment: does adding attributes improve rep’ness?</li>
        <li><b>φ<sub>DIV</sub></b> – Diversity: do attribute changes widen generation diversity?</li>
      </ul>
    </div>
  </div>
</section>


<!-- ───────────────── Large-Scale User Study ──────────────── -->
<section id="user-study" class="section is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Large-Scale User Study</h2>
    <ul class="content">
      <li>Models: Stable Diffusion 1.5 & 3.5, FLUX 1.<small>dev</small></li>
      <li>3 crowd-workers <em>per country</em> who identify with its culture.</li>
      <li>Ratings (1 – 5):<br>
        <ol style="margin-left:1.5em">
          <li><strong>Cultural Representativeness</strong> – “Could this image plausibly be found in your country?”</li>
          <li><strong>Perceptual Similarity</strong> – similarity to four real references.</li>
          <li><strong>Ground-Truth Likelihood</strong> – correctness of the artifact label.</li>
        </ol>
      </li>
      <li>Our MIA scorers show the strongest correlation with real human judgments.</li>
    </ul>
  </div>
</section>

<div class="table-container">
  <table class="table is-fullwidth is-striped is-hoverable">
    <thead>
      <tr>
        <th rowspan="2">T2I System</th>
        <th rowspan="2">ELO <span class="icon is-small" title="Higher is better"><i class="fas fa-arrow-up"></i></span></th>
        <th rowspan="2">φ*<sub>CuRe</sub> <span class="icon is-small" title="Higher is better"><i class="fas fa-arrow-up"></i></span></th>
        <th rowspan="2">φ*<sub>PS</sub> <span class="icon is-small" title="Higher is better"><i class="fas fa-arrow-up"></i></span></th>
        <th rowspan="2">φ*<sub>GT</sub> <span class="icon is-small" title="Higher is better"><i class="fas fa-arrow-up"></i></span></th>
        <th colspan="3">φ<sub>PS</sub> <span class="icon is-small" title="Lower is better"><i class="fas fa-arrow-down"></i></span></th>
        <th colspan="3">φ<sub>ITA</sub> <span class="icon is-small" title="Higher is better"><i class="fas fa-arrow-up"></i></span></th>
        <th rowspan="2">φ<sub>DIV</sub> <span class="icon is-small" title="Lower is better"><i class="fas fa-arrow-down"></i></span></th>
      </tr>
      <tr>
        <th>SL2</th>
        <th>DN2</th>
        <th>AV2</th>
        <th>SL2</th>
        <th>L2B</th>
        <th>WIT</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>FLUX.1 <small>[dev]</small></td>
        <td>1045</td>
        <td>2.814 ± 1.424</td>
        <td>2.157 ± 1.141</td>
        <td>2.251 ± 1.326</td>
        <td>0.561 ± 0.110</td>
        <td><strong>0.575 ± 0.137</strong></td>
        <td>0.523 ± 0.049</td>
        <td>0.094 ± 0.051</td>
        <td>0.218 ± 0.059</td>
        <td>0.209 ± 0.039</td>
        <td>0.708 ± 0.078</td>
      </tr>
      <tr>
        <td>Ideogram 2.0</td>
        <td>1043</td>
        <td>–</td>
        <td>–</td>
        <td>–</td>
        <td>–</td>
        <td>–</td>
        <td>–</td>
        <td>0.096 ± 0.052</td>
        <td>0.214 ± 0.067</td>
        <td>0.195 ± 0.050</td>
        <td>0.693 ± 0.072</td>
      </tr>
      <tr>
        <td>SD 3.5 Large</td>
        <td>1028</td>
        <td><strong>2.986 ± 1.439</strong></td>
        <td><strong>2.396 ± 1.228</strong></td>
        <td><strong>2.534 ± 1.393</strong></td>
        <td>0.567 ± 0.107</td>
        <td>0.604 ± 0.166</td>
        <td>0.532 ± 0.056</td>
        <td><strong>0.115 ± 0.047</strong></td>
        <td>0.251 ± 0.053</td>
        <td>0.225 ± 0.036</td>
        <td><strong>0.670 ± 0.082</strong></td>
      </tr>
      <tr>
        <td>DALL-E 3<sup>*</sup></td>
        <td>≈ 922</td>
        <td>–</td>
        <td>–</td>
        <td>–</td>
        <td>0.562 ± 0.103</td>
        <td>0.579 ± 0.143</td>
        <td>0.525 ± 0.055</td>
        <td>0.105 ± 0.051</td>
        <td>0.219 ± 0.062</td>
        <td>0.222 ± 0.041</td>
        <td>0.789 ± 0.043</td>
      </tr>
      <tr>
        <td>SDXL</td>
        <td>≈ 840</td>
        <td>–</td>
        <td>–</td>
        <td>–</td>
        <td><strong>0.557 ± 0.100</strong></td>
        <td>0.579 ± 0.151</td>
        <td><strong>0.520 ± 0.049</strong></td>
        <td>0.113 ± 0.051</td>
        <td><strong>0.255 ± 0.056</strong></td>
        <td><strong>0.230 ± 0.039</strong></td>
        <td>0.753 ± 0.042</td>
      </tr>
      <tr>
        <td>SD 1.5<sup>*</sup></td>
        <td>≈ 587</td>
        <td>2.724 ± 1.412</td>
        <td>2.094 ± 1.159</td>
        <td>2.175 ± 1.291</td>
        <td>0.559 ± 0.104</td>
        <td>0.576 ± 0.142</td>
        <td><strong>0.519 ± 0.041</strong></td>
        <td>0.107 ± 0.050</td>
        <td>0.240 ± 0.055</td>
        <td>0.229 ± 0.035</td>
        <td>0.755 ± 0.057</td>
      </tr>
      <tr>
        <td colspan="5"><strong>ρ with ELO</strong></td>
        <td>0.564</td>
        <td>–0.100</td>
        <td>0.564</td>
        <td>–0.600</td>
        <td>–0.657</td>
        <td>–0.829</td>
        <td>–0.600</td>
      </tr>
    </tbody>
  </table>
</div>
<p class="is-size-7">
  <sup>*</sup>Moderate refusal rates due to safety filters.  
  (See appendix on image-generation refusal in the paper.)
</p>

<!-- ──────────────────── Key Takeaways ──────────────────── -->
<section id="takeaways" class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Takeaways</h2>
    <div class="content">
      <ul>
        <li>Scorers like T2I systems <strong>do not work equally well across cultures</strong>.</li>
        <li>Our scorer aligns with human ratings <em>without needing ground-truth data</em>.</li>
        <li><strong>Backbone matters</strong>: using CLIP + LAION to judge a model also trained on LAION can inflate scores.</li>
        <li>Observed trade-off between <em>factuality</em> and <em>diversity</em> (cf. Kannen et al., NeurIPS ’24).</li>
      </ul>
      <p>See the paper for full benchmark tables, MLLM analysis, and exhaustive study details.</p>
    </div>
  </div>
</section>
<!-- Additional sections (results carousel, etc.) can be added later. -->

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{rege2024cure,
  author    = {Rege, Aniket and Nie, Zinnia and Ramesh, Mahesh and Raskar, Unmesh and Yu, Zhuoran and Kusupati, Aditya and Lee, Yong~Jae and Vinayak, Ramya~Korlakai},
  title     = {CuRe: Cultural Gaps in the Long‑Tail of Text‑to‑Image Models},
  journal   = {arXiv preprint arXiv:2404.xxxxx},
  year      = {2024},
  url       = {https://aniketrege.github.io/cure}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="./static/paper/CuRe_paper.pdf"><i class="fas fa-file-pdf"></i></a>
      <a class="icon-link" href="https://github.com/aniketrege" class="external-link"><i class="fab fa-github"></i></a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution‑ShareAlike 4.0 International License</a>.</p>
          <p>Please feel free to reuse the source code, but remember to link back to this page and remove our analytics snippet.</p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
